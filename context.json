{
  "project": {
    "name": "MobileLLM Privacy Interception Prototype",
    "thesis_title": "A Study of Usable Security Design through Privacy-Aware LLM-Based Interception Mechanisms for Real-Time PII Detection in End-to-End Encrypted Messaging Platforms",
    "purpose": [
      "Build a controlled research prototype to evaluate whether real-time AI privacy warnings help users notice and reflect on potential PII disclosure while composing messages.",
      "Evaluate usability and perceived trust/clarity of warnings and rewrite suggestions without removing user autonomy."
    ],
    "non_negotiables": [
      "This is NOT a real messaging app and must NOT integrate with WhatsApp or scrape real apps.",
      "No real contacts, no real message sending, no background monitoring outside the prototype.",
      "No blocking/enforcement: user must always be able to proceed."
    ]
  },
  "study_protocol": {
    "design": "Online, single-session, between-subjects user study via Prolific",
    "conditions": {
      "A_system_on": "Same chat UI + real-time highlights + warning + explanation + rewrite option",
      "B_system_off": "Same chat UI and scenarios, but no highlights, no warning, no rewrite option"
    },
    "participants": {
      "age_range": "20â€“49",
      "language": "Fluent in English",
      "device": "Smartphone only"
    },
    "procedure_summary": [
      "Consent and validation screen before tasks",
      "3 fictional multi-turn scenarios with provided reference replies",
      "Scenario-level short questions after each scenario",
      "Post-task SUS for System ON condition",
      "Completion screen + redirect/code for Prolific"
    ],
    "ethics_constraints": [
      "All content is fictional and pre-defined; participants are not asked to provide real personal messages.",
      "Store only Prolific ID and anonymized interaction logs; do not store raw PII.",
      "Participants can withdraw any time."
    ],
    "irb_reference_docs": [
      {
        "type": "Survey & flow questionnaire",
        "citation": ":contentReference[oaicite:0]{index=0}"
      },
      {
        "type": "IRB application form",
        "citation": ":contentReference[oaicite:1]{index=1}"
      },
      {
        "type": "Study protocol form",
        "citation": ":contentReference[oaicite:2]{index=2}"
      },
      {
        "type": "Participant info sheet & consent",
        "citation": ":contentReference[oaicite:3]{index=3}"
      }
    ]
  },
  "system_behavior": {
    "interaction_trigger": {
      "type": "Typing pause interception",
      "debounce_ms": 1000,
      "description": "When user stops typing for ~1.5s, run PII masking + chunking before LLM."
    },
    "mandatory_preprocessing_before_llm": {
      "notebook_reference": {
        "file_name": "gilner_chunking.ipynb",
        "role": "Provides chunking for long text and masks PIIs according to preset categories."
      },
      "requirements": [
        "The notebook logic MUST run before any LLM call.",
        "It MUST mask PII spans using the preset categories defined in the notebook.",
        "It MUST chunk long context (conversation history + draft message) into LLM-safe segments.",
        "The LLM must only receive masked/chunked content, never raw PII."
      ],
      "integration_note": "If deploying as a web app, port the notebook logic into a server-side module/service; do not run notebook code client-side."
    },
    "pipeline_order_fixed": [
      "1) Capture draft message on pause",
      "2) Chunk + mask using gilner_chunking.ipynb logic (PII categories as defined there)",
      "3) Send masked/chunked context to LLM detection endpoint",
      "4) Receive (risk_level, explanation, safer_rewrite)",
      "5) Render UI: highlight risky spans + show warning",
      "6) User chooses: Continue anyway OR Accept safer rewrite",
      "7) On send, append message to chat with timestamp/date separator; log action"
    ],
    "risk_output_format": {
      "risk_levels": ["Low", "Medium", "High"],
      "explanation_style": "Plain language, short, context-aware; avoid technical jargon and avoid revealing masked PII.",
      "rewrite_style": "Preserve intent while removing/reducing disclosure; offer refusal/deflection where appropriate."
    }
  },
  "uiux_requirements": {
    "screen_scope": "Single private 1:1 chat screen only (no chat list, no contact info page)",
    "visual_elements": [
      "WhatsApp-like header with back arrow (non-functional), profile picture, contact name",
      "Chat transcript area with message bubbles",
      "Per-message timestamps (WhatsApp style)",
      "Date separators (e.g., Today / Yesterday / full date when day changes)",
      "Bottom input bar with multiline text field + send button"
    ],
    "warning_ui": {
      "when_to_show": "On typing pause when risk >= Medium (configurable); low risk may show subtle underline only",
      "must_include": ["Risk level", "Brief explanation", "Two choices"],
      "buttons": ["Continue anyway", "Accept safer rewrite"],
      "copy_constraints": [
        "Do NOT use 'Send anyway' wording. Must be 'Continue anyway'.",
        "Do NOT block sending.",
        "Do NOT claim the system is monitoring real WhatsApp or real encryption."
      ]
    }
  },
  "out_of_scope": [
    "Real WhatsApp integration or Accessibility Service scraping real apps",
    "Group chats",
    "Attachments (images/audio/files), voice notes, stickers",
    "Phishing link clicking detection",
    "On-device LLM optimization work (beyond this thesis scope)",
    "Hard enforcement rules / auto-blocking",
    "Cultural variation modeling"
  ],
  "security_and_deployment_guidance": {
    "principles": [
      "LLM API keys must never be in client code",
      "Run masking/chunking + LLM calls server-side",
      "Use reverse proxy / serverless (e.g., Cloudflare Workers) to protect origin and rate limit"
    ],
    "logging_rules": [
      "Prefer logging masked text only (or feature-level logs), not raw user text.",
      "Store consent timestamp and condition assignment with Prolific PID."
    ]
  }
}
